{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with NLP and Sentiment Analysis ##\n",
    "\n",
    "*Notebook based off [Sentiment Analysis for Exploratory Data Analysis](https://programminghistorian.org/en/lessons/sentiment-analysis) by Zöe Wilkinson Saldaña with additional info by [Parul Pandey](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f).*\n",
    "\n",
    "Natural Language Processing (NLP) describes a broad range of techniques that involve applying computational analytical methods to textual content. (\"Natural language\" in this context just means language spoken/written by humans as opposed to a programming language, like Python). In this unit of the course, we'll be exploring many of the most popular NLP techniques, beginning with sentiment analysis. \n",
    "\n",
    "Sentiment analysis is a method of quantifing the \"sentiment,\" or emotional intensity, of words and/or phrases within a text. Some sentiment analysis tools, including the one we'll be working with today, also factor in the emotional weight of other features of language, such as punctuation marks or emojis. In general, sentiment analysis tools process a unit of text (a sentence, a paragraph, a book, an email, a song, a Tweet, etc.) and output a set of scores, or other classifications, that indicate whether that unit of text conveys a positive or negative sentiment (according to the particular algorithm employed). Some tools go as far as to quantify the *degree* of positivity or degree of negativity within a text. \n",
    "\n",
    "How might this be helpful? A researcher interested in attitudes towards a political event, for example, might use sentiment analysis to characterize how people describe that event on Twitter. Combined with geographic data, sentiment analysis can be used to make comparisons across regions. Combined with demographic data, sentiment analysis can be used to understand how different groups of people view any particular event (or issue, or individual). Sntiment analysis can be easily scaled up, which makes it possible to analyse hundreds of thousands or even millions of speech events.\n",
    "\n",
    "Like any computational tool, sentiment analysis has a number of limitations that must be taken into account. We'll explore some of those in our discussion today. But when wielding sentiment analysis *both* critically *and* creatively, it can lead to very interesting results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK and VADER ###\n",
    "\n",
    "You will be using Python along with a few tools from [NLTK](https://www.nltk.org/) (short for Natural Language Toolkit) to generate sentiment scores for the corpus that we created in Unit 1: the lyrics of the candidate playlists that we scraped from Genius.com. I've uploaded that corpus to Canvas. \n",
    "\n",
    "NLTK is a collection of Python libraries and tools that help researchers apply computational methods to texts. It's been in development since 2001--so, almost as old as you!-- and it's used very widely in the field of NLP. The tools included in NLTK range from methods of breaking up text into smaller pieces, to identifying whether a word belongs in a given language, to sample corpora (that's the plural of corpus) that researchers can use for training and development purposes. We'll be using NLTK a lot in the coming weeks. As with the previous unit, I'll introduce you to some of its features as we require them for our specific goals.   \n",
    "\n",
    "Today, we will be using one NLTK tool: [VADER](https://github.com/cjhutto/vaderSentiment) (short for Valence Aware Dictionary and sEntiment Reasoner), which generates positive, negative, and neutral sentiment scores for a given textual input.\n",
    "\n",
    "VADER has a lot of advantages over traditional methods of Sentiment Analysis, including the following:\n",
    "* It works exceedingly well on social media type text, yet readily generalizes to multiple domains;\n",
    "* It doesn’t require any training data but is constructed from a generalizable, valence-based, human-curated gold standard sentiment lexicon;\n",
    "* It is fast enough to be used online with streaming data, and;\n",
    "* It does not severely suffer from a speed-performance tradeoff.\n",
    "\n",
    "The source of the above is a very easy to read paper published by the creaters of VADER library, one of whom use to work at Georgia Tech. You can read the paper [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Lexicons, Sentiment Intenstity, and Context-Awareness ###\n",
    "\n",
    "Traditionally, sentiment analysis worked by comparing the inputted text to a list of lexical features (i.e. words) that were determined by people to be either positive or negative. These are known as *sentiment lexicons.* (It's possible to create lexicons for other types of language as well; we'll talk about this more in Unit 3, when we discuss modeling in more detail). \n",
    "\n",
    "More recently, tools have improved upon the positive/negative binary by offering more fine-tuned distinctions between varying degrees of positivity and negativity. This is known as *sentiment intensity*, and VADER does this well. For example, VADER scores “comfort” moderately positively and “euphoria” extremely positively. \n",
    "\n",
    "VADER also attempts to capture and score textual features common in informal online text such as capitalizations, exclamation points, and emoticons, as shown in the table below:\n",
    "\n",
    "![VADER table](https://programminghistorian.org/images/sentiment-analysis/sentiment-analysis1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat Emptor! ###\n",
    "\n",
    "Like any text analysis tool, VADER should be evaluated critically and in the context of the assumptions it makes about communication. VADER was developed to analyse English language microblogging and social media sites (especially Twitter). This context is more informal than, for instance, political speeches; and more contemporary than, for instance, Shakespeare. However, VADER was also developed as a general purpose sentiment analyzer, and the authors’ initial study shows it compares favorably against tools that have been trained for specific domains, use specialized lexicons, or resource-heavy machine learning techniques. That said, sentiment analysis continues to struggle to capture complex sentiments like irony, sarcasm, and mockery, when the average reader would be able to make the distinction between the literal text and its intended meaning.\n",
    "\n",
    "A few more caveats: while VADER is a good general purpose tool for English language texts, VADER only provides partial native support for non-English texts (it detects emojis/capitalization/etc., but not word choice). The developers encourage users to use automatic translation to pre-process non-English texts and then input the results into VADER. There are likely other better tools for non-English langauge texts, although I don't know them off the top of my head. \n",
    "\n",
    "### Some examples of hard-to-classify sentences ###\n",
    "\n",
    "“The premise of the film was great, but it could have been a better movie.”\n",
    "\n",
    "* What words would you identify as being associated with either positive or negative sentiment?\n",
    "* Would you say that this sentence has a positive or negative seniment? \n",
    "\n",
    "* What are some reasons that this sentence might be tricky for a sentiment analysis tool?\n",
    "\n",
    "Here's another example:\n",
    "\n",
    "“The best I can say about the movie is that it was interesting.”\n",
    "\n",
    "* What words would you identify as being associated with either positive or negative sentiment?\n",
    "* Would you say that this sentence has a positive or negative seniment? \n",
    "\n",
    "* What are some reasons that this sentence might be tricky for a sentiment analysis tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enough Talk, Time for Action! ###\n",
    "\n",
    "To use VADER, we need to import the nltk library and download and install the VADER lexicon. You do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lauren/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt') # took this out of today's lesson "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a sense of what VADER can do, let’s calculate the sentiment scores for one of the songs we scraped from Genius.com.\n",
    "\n",
    "The main component of VADER is its SentimentIntensityAnalyzer, so let's import that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You can ignore warning about not having twython installed). \n",
    "\n",
    "Technically, SentimentIntensityAnalyzer is a class, which we will use to build our own sentiment analyzer object.\n",
    "\n",
    "To do so, we call SentimentIntensityAnalyzer() and assign the output - our brand-new sentiment analyzer - to a variable, which we will name ‘sid’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this we have given \"sid\" all of the features of the VADER sentiment analysis object. It has become our sentiment analysis tool, but by a shorter name.\n",
    "\n",
    "Now, let's open up one of the lyrics files we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What you want, baby, I got it\\nWhat you need, do you know I got it?\\n\\nAll I'm askin' is for a little respect when you come home\\n(Just a little bit) Hey baby\\n(Just a little bit) when you get home\\n(Just a little bit) mister\\n(Just a little bit)\\n\\nI ain't gonna do you wrong while you're gone\\nAin't gon' do you wrong 'cause I don't wanna\\n\\nAll I'm askin' is for a little respect when you come home\\n(Just a little bit) Baby\\n(Just a little bit) When you get home\\n(Just a little bit) Yeah\\n(Just a little bit)\\n\\nI'm about to give you all of my money\\nAnd all I'm askin' in return, honey\\nIs to give me my propers when you get home\\n\\n(Just a, just a, just a, just a) Yeah, baby\\n(Just a, just a, just a, just a) When you get home\\n(Just a little bit) Yeah\\n(Just a little bit)\\n\\nOoh, your kisses, sweeter than honey\\nAnd guess what? So is my money\\n\\nAll I want you to do for me, is give it to me when you get home\\n(Re, re, re ,re) Yeah baby\\n(Re, re, re ,re) Whip it to me\\n(Respect, just a little bit) When you get home, now\\n(Just a little bit)\\n\\nR-E-S-P-E-C-T, find out what it means to me\\nR-E-S-P-E-C-T, take care, TCB, oh\\n\\n(Sock it to me, sock it to me, sock it to me, sock it to me)\\nA little respect\\n(sock it to me, sock it to me, sock it to me, sock it to me)\\nWhoa, babe\\n(Just a little bit) A little respect\\n(Just a little bit) I get tired\\n(Just a little bit) Keep on tryin'\\n(Just a little bit) You're runnin' out of fools\\n(Just a little bit) And I ain't lyin'\\n(Just a little bit)\\n(Re, re, re, re) Start when you come home\\n(Re, re, re, respect) Or you might walk in\\n(Just a little bit) And find out I'm gone\\n(Just a little bit) I gotta have\\n(Just a little bit) A little respect\\n(Just a little bit)\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./lyrics/Aretha-franklin-respect.txt\", \"r\") as file:\n",
    "    lyrics = file.read()\n",
    "\n",
    "# and just to be sure, print out what we've loaded in:\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're most interested in is called the ‘polarity score,’ which gives us a score that is either positive or negative (the two poles). This feature is built into VADER and can be requested on demand.\n",
    "\n",
    "Calling the polarity_scores method on sid with our lyrics (or, for that matter, any string) outputs a dictionary with negative, neutral, positive, and compound scores for the input text. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: 0.9342, neg: 0.035, neu: 0.875, pos: 0.09, "
     ]
    }
   ],
   "source": [
    "scores = sid.polarity_scores(lyrics)\n",
    "\n",
    "for key in sorted(scores):\n",
    "    print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! We just performed our first text analysis! \n",
    "\n",
    "But how do we analyze the analysis?\n",
    "\n",
    "VADER collects and scores negative, neutral, and positive words and features (and accounts for factors like negation along the way). The “neg”, “neu”, and “pos” values describe the fraction of weighted scores that fall into each category. In this case, VADER determined our song lyrics to consist of 3.5% negative words/features, 87.5% neutral words/features, and 9% positive words/features. \n",
    "\n",
    "VADER also sums all weighted scores to calculate a “compound” value normalized between -1 and 1; this value attempts to describe the overall affect of the entire chunk of text from strongly negative (-1) to strongly positive (1). In this case, the VADER analysis describes the song as strongly positive (.9342). We can think of this value as estimating the overall impression of an average listener when considering the song as a whole.\n",
    "\n",
    "This [post](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f) has a bit more about how VADER calculates its scores.  \n",
    "\n",
    "Let's [listen to the song](https://www.youtube.com/watch?v=6FOUqQt3Kg0) and see if we agree. \n",
    "\n",
    "### A Quick Note on Thresholds ###\n",
    "\n",
    "It can be helpful to set a minimum threshold for positivity or negativity so that you can classify a text either positive or negative. The official VADER documentation suggests a threshold of -0.5 and 0.5, which this song would meet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Appropriate Scope ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much calibration that is required of sentiment analysis. That's why I decided to begin this unit with it. But there is one important aspect of calibration to consider when employing sentiment analysis: the unit of the text being analyzed.\n",
    "\n",
    "In the case of song lyrics, for example, we might want to analyze the entire song as a single unit, or we might want to analyze each line. \n",
    "\n",
    "* What are some research questions for which you might want to look at the entire song as a whole?\n",
    "* What are some research questions for which you might want to look at each line at a time?\n",
    "\n",
    "Let's redo our sentiment analysis so that we look at each line of the song individually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What you want, baby, I got it\n",
      "neg: 0.0, neu: 0.794, pos: 0.206, compound: 0.0772, \n",
      "What you need, do you know I got it?\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "All I'm askin' is for a little respect when you come home\n",
      "neg: 0.0, neu: 0.781, pos: 0.219, compound: 0.4228, \n",
      "(Just a little bit) Hey baby\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) when you get home\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) mister\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "I ain't gonna do you wrong while you're gone\n",
      "neg: 0.307, neu: 0.693, pos: 0.0, compound: -0.4767, \n",
      "Ain't gon' do you wrong 'cause I don't wanna\n",
      "neg: 0.307, neu: 0.693, pos: 0.0, compound: -0.4767, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "All I'm askin' is for a little respect when you come home\n",
      "neg: 0.0, neu: 0.781, pos: 0.219, compound: 0.4228, \n",
      "(Just a little bit) Baby\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) When you get home\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) Yeah\n",
      "neg: 0.0, neu: 0.61, pos: 0.39, compound: 0.2315, \n",
      "(Just a little bit)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "I'm about to give you all of my money\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "And all I'm askin' in return, honey\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "Is to give me my propers when you get home\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "(Just a, just a, just a, just a) Yeah, baby\n",
      "neg: 0.0, neu: 0.804, pos: 0.196, compound: 0.296, \n",
      "(Just a, just a, just a, just a) When you get home\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) Yeah\n",
      "neg: 0.0, neu: 0.61, pos: 0.39, compound: 0.2315, \n",
      "(Just a little bit)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "Ooh, your kisses, sweeter than honey\n",
      "neg: 0.0, neu: 0.602, pos: 0.398, compound: 0.5106, \n",
      "And guess what? So is my money\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "All I want you to do for me, is give it to me when you get home\n",
      "neg: 0.0, neu: 0.92, pos: 0.08, compound: 0.0772, \n",
      "(Re, re, re ,re) Yeah baby\n",
      "neg: 0.0, neu: 0.694, pos: 0.306, compound: 0.296, \n",
      "(Re, re, re ,re) Whip it to me\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Respect, just a little bit) When you get home, now\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "R-E-S-P-E-C-T, find out what it means to me\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "R-E-S-P-E-C-T, take care, TCB, oh\n",
      "neg: 0.0, neu: 0.556, pos: 0.444, compound: 0.4939, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "(Sock it to me, sock it to me, sock it to me, sock it to me)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "A little respect\n",
      "neg: 0.0, neu: 0.263, pos: 0.737, compound: 0.4228, \n",
      "(sock it to me, sock it to me, sock it to me, sock it to me)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "Whoa, babe\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) A little respect\n",
      "neg: 0.0, neu: 0.611, pos: 0.389, compound: 0.3702, \n",
      "(Just a little bit) I get tired\n",
      "neg: 0.397, neu: 0.603, pos: 0.0, compound: -0.3892, \n",
      "(Just a little bit) Keep on tryin'\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) You're runnin' out of fools\n",
      "neg: 0.314, neu: 0.686, pos: 0.0, compound: -0.4939, \n",
      "(Just a little bit) And I ain't lyin'\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Re, re, re, re) Start when you come home\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Re, re, re, respect) Or you might walk in\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) And find out I'm gone\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) I gotta have\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "(Just a little bit) A little respect\n",
      "neg: 0.0, neu: 0.611, pos: 0.389, compound: 0.3702, \n",
      "(Just a little bit)\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n",
      "\n",
      "neg: 0.0, neu: 0.0, pos: 0.0, compound: 0.0, \n"
     ]
    }
   ],
   "source": [
    "# re-intialize VADER\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# then split our song lyrics into lines broken up by newlines \n",
    "lines = lyrics.split('\\n') # note handy built-in python string function! \n",
    "\n",
    "# We add the additional step of iterating through the list of lines and \n",
    "# calculating and printing polarity scores for each one.\n",
    "\n",
    "for line in lines:\n",
    "        print(line)\n",
    "        scores = sid.polarity_scores(line)\n",
    "        for key in scores:\n",
    "                print('{0}: {1}, '.format(key, scores[key]), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you’ll note a much more detailed picture of the sentiment in the song. \n",
    "\n",
    "For ease of interpretation, let's sort the lines by compound sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound score: 0.5106. Line: Ooh, your kisses, sweeter than honey\n",
      "Compound score: 0.4939. Line: R-E-S-P-E-C-T, take care, TCB, oh\n",
      "Compound score: 0.4228. Line: All I'm askin' is for a little respect when you come home\n",
      "Compound score: 0.4228. Line: A little respect\n",
      "Compound score: 0.3702. Line: (Just a little bit) A little respect\n",
      "Compound score: 0.296. Line: (Just a, just a, just a, just a) Yeah, baby\n",
      "Compound score: 0.296. Line: (Re, re, re ,re) Yeah baby\n",
      "Compound score: 0.2315. Line: (Just a little bit) Yeah\n",
      "Compound score: 0.0772. Line: What you want, baby, I got it\n",
      "Compound score: 0.0772. Line: All I want you to do for me, is give it to me when you get home\n",
      "Compound score: 0.0. Line: What you need, do you know I got it?\n",
      "Compound score: 0.0. Line: \n",
      "Compound score: 0.0. Line: (Just a little bit) Hey baby\n",
      "Compound score: 0.0. Line: (Just a little bit) when you get home\n",
      "Compound score: 0.0. Line: (Just a little bit) mister\n",
      "Compound score: 0.0. Line: (Just a little bit)\n",
      "Compound score: 0.0. Line: (Just a little bit) Baby\n",
      "Compound score: 0.0. Line: (Just a little bit) When you get home\n",
      "Compound score: 0.0. Line: I'm about to give you all of my money\n",
      "Compound score: 0.0. Line: And all I'm askin' in return, honey\n",
      "Compound score: 0.0. Line: Is to give me my propers when you get home\n",
      "Compound score: 0.0. Line: (Just a, just a, just a, just a) When you get home\n",
      "Compound score: 0.0. Line: And guess what? So is my money\n",
      "Compound score: 0.0. Line: (Re, re, re ,re) Whip it to me\n",
      "Compound score: 0.0. Line: (Respect, just a little bit) When you get home, now\n",
      "Compound score: 0.0. Line: R-E-S-P-E-C-T, find out what it means to me\n",
      "Compound score: 0.0. Line: (Sock it to me, sock it to me, sock it to me, sock it to me)\n",
      "Compound score: 0.0. Line: (sock it to me, sock it to me, sock it to me, sock it to me)\n",
      "Compound score: 0.0. Line: Whoa, babe\n",
      "Compound score: 0.0. Line: (Just a little bit) Keep on tryin'\n",
      "Compound score: 0.0. Line: (Just a little bit) And I ain't lyin'\n",
      "Compound score: 0.0. Line: (Re, re, re, re) Start when you come home\n",
      "Compound score: 0.0. Line: (Re, re, re, respect) Or you might walk in\n",
      "Compound score: 0.0. Line: (Just a little bit) And find out I'm gone\n",
      "Compound score: 0.0. Line: (Just a little bit) I gotta have\n",
      "Compound score: -0.3892. Line: (Just a little bit) I get tired\n",
      "Compound score: -0.4767. Line: I ain't gonna do you wrong while you're gone\n",
      "Compound score: -0.4767. Line: Ain't gon' do you wrong 'cause I don't wanna\n",
      "Compound score: -0.4939. Line: (Just a little bit) You're runnin' out of fools\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter   \n",
    "\n",
    "lines_and_compound_scores = {}\n",
    "\n",
    "for line in lines:\n",
    "    scores = sid.polarity_scores(line)\n",
    "    \n",
    "    lines_and_compound_scores.update( {line: scores['compound']} )\n",
    "\n",
    "ordered_scores = OrderedDict(sorted(lines_and_compound_scores.items(), key = itemgetter(1), reverse = True))\n",
    "\n",
    "for key in ordered_scores:\n",
    "    print(\"Compound score: \" + str(ordered_scores[key]) + \". Line: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class exercise: load in each song and find one with strongest positive sentiment and strongest negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
